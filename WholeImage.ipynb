
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import cv2
import seaborn as sns

from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras import optimizers
from keras import losses

import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D
from tensorflow.keras.applications.vgg19 import VGG19 # VGG19
from tensorflow.keras.utils import plot_model


from IPython.display import Image
from google.colab import drive
drive.mount('/content/drive')
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
def show_image(image):
    plt.imshow(image)
    plt.show()
def create_mias_dataset(file_path: str) -> pd.DataFrame:
    ''' Creates a dataset with the data about the scans '''
    # create a dataset
    mammo = pd.read_table(file_path, delimiter='\s', engine='python')
    # rename the class column to avoid conflicts with the class keyword in python
    mammo.columns = ['refnum', 'bg', 'ab_class', 'severity', 'x', 'y', 'radius']
    # fill null severity with A for NORM class
    # mammo.severity = mammo.severity.fillna('A')
    # drop duplicates
    mammo.drop_duplicates(subset='refnum', keep='first', inplace=True)
    # set refnum as index
    # mammo.set_index(keys='refnum', drop=True, inplace=True)

    return mammo
mias = create_mias_dataset('/content/drive/MyDrive/Dataset/Info.txt')
mias
refnum	bg	ab_class	severity	x	y	radius
0	mdb001	G	CIRC	B	535.0	425.0	197.0
1	mdb002	G	CIRC	B	522.0	280.0	69.0
2	mdb003	D	NORM	None	NaN	NaN	NaN
3	mdb004	D	NORM	None	NaN	NaN	NaN
4	mdb005	F	CIRC	B	477.0	133.0	30.0
...	...	...	...	...	...	...	...
325	mdb318	D	NORM	None	NaN	NaN	NaN
326	mdb319	D	NORM	None	NaN	NaN	NaN
327	mdb320	D	NORM	None	NaN	NaN	NaN
328	mdb321	D	NORM	None	NaN	NaN	NaN
329	mdb322	D	NORM	None	NaN	NaN	NaN
322 rows × 7 columns

# drop nan in severity which indicate norm 
mias.dropna(subset=['severity'], inplace=True)
mias.reset_index(inplace=True)
mias.drop(['index'],axis=1,inplace=True)
mias
refnum	bg	ab_class	severity	x	y	radius
0	mdb001	G	CIRC	B	535.0	425.0	197.0
1	mdb002	G	CIRC	B	522.0	280.0	69.0
2	mdb005	F	CIRC	B	477.0	133.0	30.0
3	mdb010	F	CIRC	B	525.0	425.0	33.0
4	mdb012	F	CIRC	B	471.0	458.0	40.0
...	...	...	...	...	...	...	...
110	mdb274	F	MISC	M	127.0	505.0	123.0
111	mdb290	D	CIRC	B	337.0	353.0	45.0
112	mdb312	F	MISC	B	240.0	263.0	20.0
113	mdb314	F	MISC	B	518.0	191.0	39.0
114	mdb315	D	CIRC	B	516.0	447.0	93.0
115 rows × 7 columns

# B = 0 index
# M = 1 index
lb = LabelEncoder()
mias['severity'] = lb.fit_transform(mias['severity'])
encoded_labels  = to_categorical(mias['severity'])
# images path
path= '/content/drive/MyDrive/Dataset/all-mias/'
no_angles = 360
def read_images_labels():
  # define the every images filepaths in to list
  images = []
  labels=[]

  for i in range(len(mias)):

    image_address= path + mias.refnum[i]+ '.pgm'
    img = cv2.imread(image_address,1)
    img = cv2.resize(img, (224,224))   #resize image
    rows, cols,color = img.shape

    for angle in range(0,no_angles,8):

      M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)    #Rotate 0 degree
      img_rotated = cv2.warpAffine(img, M, (cols, rows))

      images.append(img_rotated)
      labels.append(encoded_labels[i])

  return images, labels
X, Y = read_images_labels()
X = np.asarray(X)
X.shape
(5175, 224, 224, 3)
Y = np.array(Y)
Y.shape
(5175, 2)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=2021,shuffle=True)
base_model = VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)
model=Sequential()
model.add(base_model)
model.add(Dropout(0.2))
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(1024,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1024,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1024,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(2,activation='softmax'))

for layer in base_model.layers:
    layer.trainable = False

model.summary()
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 vgg19 (Functional)          (None, 7, 7, 512)         20024384  
                                                                 
 dropout (Dropout)           (None, 7, 7, 512)         0         
                                                                 
 flatten (Flatten)           (None, 25088)             0         
                                                                 
 batch_normalization (BatchN  (None, 25088)            100352    
 ormalization)                                                   
                                                                 
 dense (Dense)               (None, 1024)              25691136  
                                                                 
 batch_normalization_1 (Batc  (None, 1024)             4096      
 hNormalization)                                                 
                                                                 
 activation (Activation)     (None, 1024)              0         
                                                                 
 dropout_1 (Dropout)         (None, 1024)              0         
                                                                 
 dense_1 (Dense)             (None, 1024)              1049600   
                                                                 
 batch_normalization_2 (Batc  (None, 1024)             4096      
 hNormalization)                                                 
                                                                 
 activation_1 (Activation)   (None, 1024)              0         
                                                                 
 dropout_2 (Dropout)         (None, 1024)              0         
                                                                 
 dense_2 (Dense)             (None, 1024)              1049600   
                                                                 
 batch_normalization_3 (Batc  (None, 1024)             4096      
 hNormalization)                                                 
                                                                 
 activation_2 (Activation)   (None, 1024)              0         
                                                                 
 dropout_3 (Dropout)         (None, 1024)              0         
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 47,929,410
Trainable params: 27,848,706
Non-trainable params: 20,080,704
_________________________________________________________________
from tensorflow.keras.utils import model_to_dot 
from IPython.display import Image

plot_model(model, to_file='model_architecture.png' ,show_shapes=True, show_layer_names=True)
Image(filename='model_architecture.png')

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
es = EarlyStopping(monitor='val_loss', mode='min', patience=6,restore_best_weights=True, verbose=1)
model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train,validation_split=0.15,shuffle=True, epochs=40, batch_size=128,callbacks=[es])
Epoch 1/40
30/30 [==============================] - 98s 2s/step - loss: 0.6227 - accuracy: 0.6851 - val_loss: 1.1243 - val_accuracy: 0.8000
Epoch 2/40
30/30 [==============================] - 37s 1s/step - loss: 0.1343 - accuracy: 0.9559 - val_loss: 0.5463 - val_accuracy: 0.8864
Epoch 3/40
30/30 [==============================] - 37s 1s/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.2933 - val_accuracy: 0.9379
Epoch 4/40
30/30 [==============================] - 37s 1s/step - loss: 0.0549 - accuracy: 0.9802 - val_loss: 0.3626 - val_accuracy: 0.9106
Epoch 5/40
30/30 [==============================] - 37s 1s/step - loss: 0.0494 - accuracy: 0.9813 - val_loss: 0.2608 - val_accuracy: 0.9394
Epoch 6/40
30/30 [==============================] - 37s 1s/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.1719 - val_accuracy: 0.9455
Epoch 7/40
30/30 [==============================] - 37s 1s/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.2035 - val_accuracy: 0.9424
Epoch 8/40
30/30 [==============================] - 37s 1s/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1598 - val_accuracy: 0.9545
Epoch 9/40
30/30 [==============================] - 37s 1s/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.1104 - val_accuracy: 0.9667
Epoch 10/40
30/30 [==============================] - 37s 1s/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.1239 - val_accuracy: 0.9652
Epoch 11/40
30/30 [==============================] - 37s 1s/step - loss: 0.0163 - accuracy: 0.9936 - val_loss: 0.1253 - val_accuracy: 0.9591
Epoch 12/40
30/30 [==============================] - 37s 1s/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.1092 - val_accuracy: 0.9667
Epoch 13/40
30/30 [==============================] - 37s 1s/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.0982 - val_accuracy: 0.9712
Epoch 14/40
30/30 [==============================] - 37s 1s/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.1125 - val_accuracy: 0.9712
Epoch 15/40
30/30 [==============================] - 37s 1s/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.1884 - val_accuracy: 0.9636
Epoch 16/40
30/30 [==============================] - 37s 1s/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.1399 - val_accuracy: 0.9652
Epoch 17/40
30/30 [==============================] - 37s 1s/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.1049 - val_accuracy: 0.9652
Epoch 18/40
30/30 [==============================] - 37s 1s/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.1020 - val_accuracy: 0.9712
Epoch 19/40
30/30 [==============================] - 37s 1s/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0772 - val_accuracy: 0.9803
Epoch 20/40
30/30 [==============================] - 37s 1s/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0976 - val_accuracy: 0.9712
Epoch 21/40
30/30 [==============================] - 37s 1s/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.0720 - val_accuracy: 0.9803
Epoch 22/40
30/30 [==============================] - 36s 1s/step - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.0863 - val_accuracy: 0.9742
Epoch 23/40
30/30 [==============================] - 37s 1s/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0926 - val_accuracy: 0.9773
Epoch 24/40
30/30 [==============================] - 37s 1s/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.0975 - val_accuracy: 0.9727
Epoch 25/40
30/30 [==============================] - 37s 1s/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1081 - val_accuracy: 0.9712
Epoch 26/40
30/30 [==============================] - 37s 1s/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.1076 - val_accuracy: 0.9727
Epoch 27/40
30/30 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9981Restoring model weights from the end of the best epoch: 21.
30/30 [==============================] - 37s 1s/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.1399 - val_accuracy: 0.9606
Epoch 00027: early stopping
loss_value , accuracy = model.evaluate(x_test, y_test)

print('Test_loss_value = ' +str(loss_value))
print('test_accuracy = ' + str(accuracy))
25/25 [==============================] - 20s 406ms/step - loss: 0.1140 - accuracy: 0.9717
Test_loss_value = 0.11400675028562546
test_accuracy = 0.9716859459877014
#%% PLOTTING RESULTS (Train vs Validation)
import matplotlib.pyplot as plt
def Train_Val_Plot(acc,val_acc,loss,val_loss):
    
    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))
    fig.suptitle(" MODEL'S METRICS VISUALIZATION ")

    ax1.plot(range(1, len(acc) + 1), acc)
    ax1.plot(range(1, len(val_acc) + 1), val_acc)
    ax1.set_title('History of Accuracy')
    ax1.set_xlabel('Epochs')
    ax1.set_ylabel('Accuracy')
    ax1.legend(['training', 'validation'])


    ax2.plot(range(1, len(loss) + 1), loss)
    ax2.plot(range(1, len(val_loss) + 1), val_loss)
    ax2.set_title('History of Loss')
    ax2.set_xlabel('Epochs')
    ax2.set_ylabel('Loss')
    ax2.legend(['training', 'validation'])
    plt.show()
    

Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],
               history.history['loss'],history.history['val_loss'])

predictions = model.predict(x_test)
y_pred = [np.argmax(w) for w in predictions]
y_test = [np.argmax(w) for w in y_test]
cm1 = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(12, 6))
plt.title('the confusion matrix of the model in the train')
sns.heatmap(cm1, annot = True, fmt = 'g' ,vmin = 0, cmap = 'binary')
<matplotlib.axes._subplots.AxesSubplot at 0x7f8febddc290>

label_mapping = {
    1: 'M',
    0: 'B'
}

classification_report_model = classification_report(y_test, y_pred, target_names=label_mapping.values())
print(classification_report_model)
              precision    recall  f1-score   support

           M       0.99      0.96      0.97       427
           B       0.96      0.98      0.97       350

    accuracy                           0.97       777
   macro avg       0.97      0.97      0.97       777
weighted avg       0.97      0.97      0.97       777

# tf.saved_model.save(model,'model')
# model.save('Final_model.h5')
